Let us have a look at a number of studies that leverage various techniques from
the field of machine learning in order to facilitate resource management in
computer systems.

In \cite{coskun2008}, temperature forecasting is based on an autoregressive
moving-average model \cite{hastie2009}, enabling the development of an efficient
thermal management strategy for multiprocessor systems. The work in
\cite{kumar2010} enhances runtime thermal management by providing an on-chip
temperature predictor based on feed-forward neural networks \cite{hastie2009}.
The analysis and mitigation of the impact of process variation undertaken in
\cite{juan2014} are facilitated by a linear regression model \cite{hastie2009}
trained on leakage-power measurements with the goal of predicting peak
temperatures.

Closer to our work, the work in \cite{dabbagh2015} is concerned with cloud data
centers. The authors propose a framework for predicting the number of
virtual-machine requests together with the required amount of \up{CPU} and
memory. The framework makes use of k-means clustering \cite{hastie2009} for
identifying different types of requests, and then it uses Wiener filters in
order to estimate the workload with respect to each identified type.

Similar to \cite{dabbagh2015}, the work in \cite{ismaeel2015} is focused on
forecasting virtual-machine requests in cloud data centers and relies on k-means
clustering as the first step. Unlike \cite{dabbagh2015}, the main workhorse in
the case of \cite{ismaeel2015} is extreme learning machines, which are
feed-forward neural networks mentioned earlier.

An ensemble model \cite{hastie2009} is presented in \cite{cao2014} targeted at
predicting the \up{CPU} usage in cloud environments. It relies on multiple
models including an exponential smoothing, auto regressive, weighted nearest
neighbors, and most similar pattern model. The final predictions are obtained by
combing the predictions from these models by means of a scoring algorithm.

It can be seen in the above that, in general, machine learning has been
extensively utilized for aiding the design of resource managers of computer
systems. However, as mentioned in \sref{introduction}, the most recent
advancements in machine learning have not been sufficiently explored in this
context yet. In particular, the utility of neural networks have been studied
only marginally: feed-forward networks, as in \cite{kumar2010, ismaeel2015}, are
arguably the simplest and least powerful members of this rich family of
techniques.

In addition, note that the predictions delivered by \cite{dabbagh2015,
ismaeel2015, cao2014} are coarse, aggregative. The corresponding techniques
treat virtual-machine requests or computational resources as a fluid and predict
the amount of this fluid that will arrive or be needed at the next time step. It
means that the aforementioned techniques are not capable of characterizing
individual tasks. Such fine-grained information, however, can be of help for the
resource manager of the computer cluster under consideration.

To conclude, only primitive architectures of neural networks have been
considered in the literature on resource management, and only aggregative
prediction has been addressed so far. Thus, there is a need for further
exploration and development.

Our work makes the following major contribution.
\begin{itemize}
\item We present a pipeline for working with a large data set that makes the
data readily accessible for machine-learning undertakings, and we apply it to a
data set of real resource-usage traces collected in a large computer cluster.

\item We present a model for making fine-grained long-range prediction of the
cluster's resource usage that relies on the state-of-the-art recurrent neural
networks.

\item We open-source the whole infrastructure that we have developed for data
processing and modeling \cite{sources}.
\end{itemize}
To the best of our knowledge, we are the first ones to investigate the utility
of recurrent neural networks for predicting the resource usage in a computer
cluster. In addition, to the best of our knowledge, we are the first ones to
address this prediction at the level of individual tasks executed in the
cluster.
